---
layout: post
category: weekly
tags: 周刊 AI Agent
title: "周刊第19期: 一起学习 MCP"
subtitle: ""
date: "2025-09-08 20:56:00 +0800"
image: weeklies/18-wanweigang.jpg
---

本文为周刊第19期，前期周刊参见：[周刊系列](/weeklies/)。

我最近学习了 MCP(Model Context Protocol, 模型上下文协议)的一系列文档、书籍和文章，本期周刊则梳理总结下相关知识，一起来学习了解下 MCP 究竟是什么，能解决什么问题，基本概念和内部原理是什么，以及生态和当前的发展情况。

<图>

## MCP 的起源

OpenAI发布ChatGPT让人们看到了大语言模型(LLM)的强大能力，而ChatGPT也在短时间内成为了超级互联网应用，甚至取代了人们寻求知识的习惯，很多人在互联网上搜索信息开始不再优先使用搜索引擎，而是从ChatGPT等AI对话类应用获取信息。

但大模型也有一个弱点，那就是它是通过历史数据训练成的，其知识在训练时就已经固定，无法获取训练之后的新信息。正如Anthropic在[推出MCP的介绍文章](https://www.anthropic.com/news/model-context-protocol)中说的那样：“即便是最先进的模型，也受限于与数据隔绝——被困在信息孤岛和遗留系统之后。”为了解决这一问题，行业采用了两个解决方案。第一个解决方案是模型微调，也就是在基础大模型上加入一些新的数据集进行增量训练，这种场景仍需要进行训练后再部署，一则成本比较高，二则是实时性比较高的场景也不能满足。而另一个解决方案就是上下文补充，在与大模型问答的时候，为大模型提供外部知识库信息作为输入上下文，让大模型根据上下文信息进行推理，从而弥补大模型原有知识的不足。

为大模型补充上下文的方案有很多，比如我们在与ChatGPT等AI应用对话时，大模型能结合之前对话的上下文来回答，这是因为AI应用将对话内容进行了存储记录，压缩处理成后续问答的上下文给到大模型。这种方法受限于用户的对话内容，若想要获得更广泛的上下文，那就需要更进一步的技术如RAG.

RAG(Retrival Augmented Generation, 检索增强生成)是一种让大模型结合外部知识库的方法，RAG 所代表的三个缩写词就是它的工作原理：Retrival(检索)：首先，当用户发出提问时，AI应用将问题通过向量化检索的方式获得与问题相关的文档知识；Augmented(增强)：然后，AI应用把检索到的资料拼接到Prompt中，作为增强上下文；Generation(生成)：最后，模型基于问题+外部资料信息生成答案。RAG的优势在于不需要训练模型，能够接入最新的知识，并保持知识库的更新。但其限制在于，RAG依赖于检索到信息的质量，同时还要求检索过程足够高效，但实际应用中，检索速度和检索准确率是比较大的技术挑战。另外，RAG在技术上还依赖建立并维护一个实时更新的向量数据库，而当知识库规模化后，其成本、性能、检索精度都可能成为瓶颈。

<图> 

![Retrieval-Augmented-Generation.jpg](attachment:239a3062-59d2-4542-bd9b-dadd1937debb:Retrieval-Augmented-Generation.jpg)

2023年6月OpenAI在其模型API中更新发布了函数调用(function calling)能力，它允许大模型将自然语言请求转换为函数调用，让AI应用可以调用外部工具。其工作原理是：1) AI应用开发者定义函数列表，包括名称、用途、参数类型；2) 用户发出问题，AI应用将函数列表作为上下文发送给大模型；3) 大模型根据用户输入判断需要调用的函数，生成调用参数；4) AI应用执行该函数并将结果发送给大模型，作为补充上下文信息供大模型生成最终的答案。这一特性也极大扩展了大模型的能力边界，通过函数调用的方式，大模型能够外挂各种外部数据源，同时还能执行各种类型的操作。

<图>

![openai-function-calling.jpeg](attachment:e04eb926-4365-4906-9650-e522f098367a:openai-function-calling.jpeg)

在OpenAI推出函数调用机制后，各大模型厂商纷纷跟进，分别都支持了函数调用机制。但随之而来也有一些问题，因为函数调用是一种机制，而非标准，因此虽然函数定义都是JSON格式，但个大模型厂商实现方式不同，结构差异很大；另外，需要开发者为每种模型或AI应用编写特定的适配代码。这些都是函数调用机制在实际应用场景需要迫切解决的问题。

不过，OpenAI在推出函数调用机制后，没有更进一步统一行业标准，而是着急推出GPTs的生态战略。OpenAI在推出函数调用后的同年11月，也就是2023年开发者大会上，推出了GPTs, 这是专为特定任务创建的ChatGPT 的定制版本，并且开发者可以打造自己的GPTs, OpenAI CEO 山姆·奥特曼还特意演示了如何在几分钟内创建了一个商业顾问GPTs。到次年2024年1月，OpenAI开放GPTs Store, 上线不久，商店内的GPTs就达到了300万。但巨大的数量并没有产生实质性的效果，有报道称，95%的GPTs应用的用户数不超过100人，绝大多数GPTs的用户只有一、二人。这也暴露了GPTs的问题，GPTs想法的初衷是好的，普通用户通过简单的操作比如调整提示词便可以创建专属的AI应用，但这种低门槛也就意味着大量低质量的应用被快速构建出来，实际上没有什么用处。在实际的工作和生活场景，AI应用需要与各种IT工具交互才能产生真正的价值。

OpenAI所忽视的标准被Anthropic搞出来了。2024年11月，[Anthropic推出MCP](https://www.anthropic.com/news/model-context-protocol)，即模型上下文协议(Model Context Protocol)，这是一个开放标准，用一个统一标准的协议，让大模型应用可以安全、方便地访问外部数据并进行工具连接。可以认为，MCP是在函数调用基础上做的升级和抽象。

## MCP 的基本概念

MCP 解决方案在架构上有三个角色：主机（MCP Host）、客户端（MCP Client）、服务器（MCP Server），它们通过 MCP 协议进行协作。MCP 主机一般是AI应用，如ChatGPT等AI对话应用，或是智能体Agent，或者如Cursor等AI IDE等。MCP 服务器则是负责对接外部数据或工具服务，并通过MCP标准数据格式将内容发送给MCP客户端。MCP 客户端则是MCP主机与MCP服务器连接的桥梁，它附属于主机上，由主机任务创建并调度，从而实现AI应用与外部数据或工具服务的交互。

对于MCP的这些概念，[网上有张图](https://norahsakal.com/blog/mcp-vs-api-model-context-protocol-explained/)非常形象的解释了它们的关系。MCP就像是电脑的拓展坞，有了它之后，无论是远程调用的服务（如数据库、Web服务、远程系统）还是本地服务（文件系统、本地工具）都可以被主机（AI应用）所调用。

<图>

![mcp-overview.png](attachment:74b50d02-2948-47e3-ae7b-33bedf3a9cdc:mcp-overview.png)

相比之下，前面提到的函数调用或其他API调用方式就需要AI应用做定制的适配。

<图>

![api-overview.png](attachment:9e757ba8-57b9-432b-bd33-52e39d281394:api-overview.png)

MCP官方文档中对MCP架构描述如下。MCP客户端与MCP服务器一对一连接。

```mermaid
graph TB
    subgraph "MCP Host (AI Application)"
        Client1["MCP Client 1"]
        Client2["MCP Client 2"]
        Client3["MCP Client 3"]
    end

    Server1["MCP Server 1<br/>(e.g., Sentry)"]
    Server2["MCP Server 2<br/>(e.g., Filesystem)"]
    Server3["MCP Server 3<br/>(e.g., Database)"]

    Client1 ---|"One-to-one<br/>connection"| Server1
    Client2 ---|"One-to-one<br/>connection"| Server2
    Client3 ---|"One-to-one<br/>connection"| Server3

    style Client1 fill:#e1f5fe
    style Client2 fill:#e1f5fe
    style Client3 fill:#e1f5fe
    style Server1 fill:#f3e5f5
    style Server2 fill:#f3e5f5
    style Server3 fill:#f3e5f5

```

MCP协议包含两层：数据层和传输层。数据层定义了基于 JSON-RPC 的“客户端-服务器”通信协议，包括生命周期管理、核心原语（tools, resources, prompts）、通知机制。传输层定义了通信机制与通道，包括连接建立、消息封装、认证等。MCP支持两种传输机制。一种是对本地数据服务的STDIO 传输，通过标准输入/输出流在同一台机器上的本地进程间通信，没有网络开销。另一种是对远程数据服务的流式 HTTP 传输。

数据层方面，由于MCP是有状态协议，因此需要生命周期管理，以便于协商客户端与服务器所支持的能力。协议支持实时通知，以实现服务器与客户端之间的动态更新。例如，当服务器的可用工具发生变化（新增、修改、下线）时，服务器可以发送工具更新通知，告知已连接的客户端这些变化。

### 原语 Primitives

MCP协议最重要的概念是原语，原语定义了客户端和服务器能够互相提供的内容，规定了可以与 AI 应用共享哪些上下文信息，以及可以执行哪些范围内的操作。

服务器的三个核心原语：

- **工具（Tools）**：可执行的函数，AI 应用可以调用它们执行操作（例如文件操作、API 调用、数据库查询）。
- **资源（Resources）**：为 AI 应用提供上下文信息的数据源（例如文件内容、数据库记录、API 响应）。
- **提示词（Prompts）**：可复用的模版，用于组织与大语言模型的交互（例如系统提示词、少样本示例提示词等）。

每种原语都包含相关联的方法用于发现（*/list）和获取（*/get），比如用于工具发现的（tools/list），还有一些方法适用于特定原语，比如工具调用（tools/call）。MCP 客户端则使用 */list 方法来发现所有可用原语。

比如我们实现一个行程助手的MCP服务器，在工具里可以定义一个搜索航班的工具：

```json
{
  name: "searchFlights",
  description: "Search for available flights",
  inputSchema: {
    type: "object",
    properties: {
      origin: { type: "string", description: "Departure city" },
      destination: { type: "string", description: "Arrival city" },
      date: { type: "string", format: "date", description: "Travel date" }
    },
    required: ["origin", "destination", "date"]
  }
}
```

而AI应用里就可以使用该工具来搜索航班：

```json
searchFlights(origin: "NYC", destination: "Barcelona", date: "2024-06-15")
```

客户端也定义了三个核心原语：

- **采样（Sampling）**：让服务器无需集成或对接大模型，而是允许服务器请求客户端（已拥有模型访问能力）代表其处理任务。这样客户端就能完全掌控用户权限与安全措施。
- **根目录（Roots）**：根目录定义了文件系统的边界，允许客户端告知服务器其操作范围，以便保持安全边界。
- **引导（Elicitation）**：使服务器能在交互过程中向用户请求特定信息，从而构建更动态、更灵活的工作流。

除了这三个核心原语，客户端还可以定义如日志（Logging, 允许服务器向客户端发送日志消息，用于调试与监控）等原语。

### MCP运作过程示例

下面以一个MCP “客户端-服务器”的交互示例来解释MCP的运作过程。

#### 1. 初始化 (生命周期管理)

MCP 交互从生命周期管理的能力交互握手开始，首先是客户端发送 `initialize` 请求来建立连接并协商支持的能力。

```json
{
  "jsonrpc": "2.0",
  "id": 1,
  "method": "initialize",
  "params": {
    "protocolVersion": "2025-06-18",
    "capabilities": {
      "elicitation": {}
    },
    "clientInfo": {
      "name": "example-client",
      "version": "1.0.0"
    }
  }
}
```

而服务器也会回应：

```json
{
  "jsonrpc": "2.0",
  "id": 1,
  "result": {
    "protocolVersion": "2025-06-18",
    "capabilities": {
      "tools": {
        "listChanged": true
      },
      "resources": {}
    },
    "serverInfo": {
      "name": "example-server",
      "version": "1.0.0"
    }
  }
}
```

capabilities 里包含着双方声明的原语，即暴露的能力。在这个例子中，客户端声明了 elicitation 原语，表明服务器可以处理用户交互请求，而服务器声明支持 tools 和 resources 原语，而 tools/list_changed 则说明当工具列表更改时，服务器会发送消息通知。

初始化成功后，客户端会发送通知表明已准备就绪：

```json
{
  "jsonrpc": "2.0",
  "method": "notifications/initialized"
}
```

在初始化阶段，AI应用会建立通过客户端管理建立与各服务器的链接并存储它们的能力信息以决定后续调用哪些服务器的功能。

#### 2. 工具发现（原语）

链接一旦建立，客户端就可以发送 `tools/list` 请求发现服务器提供的工具。

```json
{
  "jsonrpc": "2.0",
  "id": 2,
  "method": "tools/list"
}
```

服务器回复：

```json
{
  "jsonrpc": "2.0",
  "id": 2,
  "result": {
    "tools": [
      {
        "name": "calculator_arithmetic",
        "title": "Calculator",
        "description": "Perform mathematical calculations including basic arithmetic, trigonometric functions, and algebraic operations",
        "inputSchema": {
          "type": "object",
          "properties": {
            "expression": {
              "type": "string",
              "description": "Mathematical expression to evaluate (e.g., '2 + 3 * 4', 'sin(30)', 'sqrt(16)')"
            }
          },
          "required": ["expression"]
        }
      },
      {
        "name": "weather_current",
        "title": "Weather Information",
        "description": "Get current weather information for any location worldwide",
        "inputSchema": {
          "type": "object",
          "properties": {
            "location": {
              "type": "string",
              "description": "City name, address, or coordinates (latitude,longitude)"
            },
            "units": {
              "type": "string",
              "enum": ["metric", "imperial", "kelvin"],
              "description": "Temperature units to use in response",
              "default": "metric"
            }
          },
          "required": ["location"]
        }
      }
    ]
  }
}
```

服务器的响应包含一个tools数组，里面是各工具的元数据信息，包括每个工具在该服务器内的唯一标识符 `name`, 名称 `title`, 描述 `description`, 以及输入参数的 JSON Schema 定义 `inputSchema`.  

AI 应用会将所有 MCP 服务器提供的工具合并成统一的工具注册表，供大模型获取并准备后续调用。

#### 3. 工具调用（原语）

获得工具信息后，客户端可以通过 `tools/call` 方法调用工具。

```json
{
  "jsonrpc": "2.0",
  "id": 3,
  "method": "tools/call",
  "params": {
    "name": "weather_current",
    "arguments": {
      "location": "San Francisco",
      "units": "imperial"
    }
  }
}
```

相应地，服务器在执行工具成功后会反馈工具调用结果。

```json
{
  "jsonrpc": "2.0",
  "id": 3,
  "result": {
    "content": [
      {
        "type": "text",
        "text": "Current weather in San Francisco: 68°F, partly cloudy with light winds from the west at 8 mph. Humidity: 65%"
      }
    ]
  }
}
```

当大模型在对话中决定要调用工具，AI应用会拦截工具调用，将请求路由到对应的MCP 服务器，执行工具调用，并将结果返回给大模型，这样大模型就能够访问到外部的实时数据。

#### 4. 实时更新（通知）

MCP 支持实时更新，允许服务器主动告知客户端变化，而不是等待客户端请求。

比如当服务器工具发生变化，服务器可以发送通知给客户端：

```json
{
  "jsonrpc": "2.0",
  "method": "notifications/tools/list_changed"
}
```

通知消息无需响应。不过客户端在收到工具变化通知后，一般会立刻向服务器发送请求获取工具列表。

## MCP 生态

MCP自发布以来，便受到了众多开发者的参与，而各AI应用厂商和各大模型厂商也纷纷跟进，变成了行业的事实标准，也因此形成了丰富的生态，从配套工具到解决方案，从市场到周边，这里也列举一些。

### 配套工具

MCP官方提供了TypeScript、Python等九种语言的[SDK](https://modelcontextprotocol.io/docs/sdk)，另外还提供了调试工具和命令行工具，通过这些配套工具可以很方便的开发MCP服务器和客户端。我根据《这就是MCP》的指导也很快开发了个flomo的MCP服务器，代码在 https://github.com/hutusi/flomo-mcp, 这里就不展开解释。

### MCP应用市场

MCP官方没有推出MCP应用市场，只是在GitHub上用一个[README收集了MCP服务器清单](https://github.com/modelcontextprotocol/servers?tab=readme-ov-file#model-context-protocol-servers)，不过有很多第三方的MCP市场，如 smithery.ai, MCP.so, MCPMarket.com, [modelscope.cn/mcp](https://modelscope.cn/mcp) 等。其中，目前可能是MCP服务器收录最多的mcp.so 来自于一位网名为艾逗笔的技术极客之手，他从腾讯离职后做独立开发。去年11月底，Anthropic发布MCP，艾逗笔认真阅读官方文档后[突发奇想](https://web.okjike.com/u/35224A78-8B11-469E-B307-16B58688FBEC/post/675287728dc1346967bf59a5)，觉得可以建一个MCP的导航站，于是立马上手，花了两个小时mcp.so 就上线了，不得不说，在AI时代有想法又能够动手的话生产效率是惊人的。

MCP应用市场解决了MCP服务器收集、分类、发现的问题，在MCP生态中就像是手机应用市场。

### 企业级MCP解决方案

不过，我觉得MCP官方没有推出应用市场的原因，除了试图保持中立外，还有一个原因是互联网开放的MCP应用市场内容运营和治理很难做，很难保证用户上传的MCP服务器不存在安全风险和质量隐患，而MCP更具有商业价值的场景是在企业内部，MCP可以帮助企业内部的AI应用在实际作业中产生效果。因此，有不少企业在探索企业级的MCP解决方案，其中比较有代表性的是阿里云的Higress+Nacos方案。

Higress是阿里云开源的云原生API网关，基于 Envoy+Istio 的架构演进而来，最初用于阿里内部的流量网关场景。在MCP场景下，Higress被用作为统一网关，让外部的AI应用调用时只接入一个网关，内部的MCP服务器的地址和安全策略都隐藏在背后。而 Nacos 是阿里云开源的服务发现与配置管理平台，在MCP场景下，就可以作为MCP服务器的注册中心。各业务系统将MCP服务器注册到Nacos上，由Higress自动发现并路由；当业务系统的MCP服务器地址变更或变更时，Nacos自动更新，而外部AI应用调用则无感知。类似下面这样的架构:

```bash
外部 AI 应用 
      │
      ▼
  [Higress 网关]  ← 鉴权、限流、审计
      │
      ▼
  [服务发现：Nacos]
      │
      ▼
  [内部 MCP Server 群]
   ├── 文档库 Server
   ├── ERP Server
   ├── CRM Server
   └── Git Server

```

### MCP 和 A2A

除了MCP外，[AI应用互操作协议](https://arxiv.org/pdf/2505.02279)还有A2A (Agent-to-Agent Protocol)、ACP (Agent Communication Protocol)、ANP (Agent Network Protocol)等，这里主要谈一下A2A协议。

A2A协议由Google在2025年4月发布，该协议主要的目的是提供一种标准化的协议支持Agent之间协作与通信，也就是说，A2A适用于多Agent场景。在A2A协议中，规定Agent需要公开一个Agent Card，以JSON格式描述，包含它的能力、模态和限制条件等。

不过，A2A并不是取代MCP，它们之间也不是互斥的，二者可以形成互补，两者的关系如下图所示。

<图>


## 参考

《这就是MCP》
...

*********************************************

> 昔日我曾如此苍老，如今才是风华正茂。
> 
> I was so much older then，I'm younger than that now.
> 
> -- Bob Dylan 《 *My Back Pages* 》
> 
